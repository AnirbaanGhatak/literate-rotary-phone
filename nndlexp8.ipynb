{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 09:10:52.364136: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-23 09:10:54.599875: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-23 09:10:54.599962: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-23 09:10:54.962941: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-23 09:10:55.689410: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-23 09:10:55.690389: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-23 09:10:59.042804: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Layer Name: input_5, Input Shape: [(None, None, None, 3)], Output Shape: [(None, None, None, 3)]\n",
      "Layer Name: block1_conv1, Input Shape: (None, None, None, 3), Output Shape: (None, None, None, 64)\n",
      "Layer Name: block1_conv2, Input Shape: (None, None, None, 64), Output Shape: (None, None, None, 64)\n",
      "Layer Name: block1_pool, Input Shape: (None, None, None, 64), Output Shape: (None, None, None, 64)\n",
      "Layer Name: block2_conv1, Input Shape: (None, None, None, 64), Output Shape: (None, None, None, 128)\n",
      "Layer Name: block2_conv2, Input Shape: (None, None, None, 128), Output Shape: (None, None, None, 128)\n",
      "Layer Name: block2_pool, Input Shape: (None, None, None, 128), Output Shape: (None, None, None, 128)\n",
      "Layer Name: block3_conv1, Input Shape: (None, None, None, 128), Output Shape: (None, None, None, 256)\n",
      "Layer Name: block3_conv2, Input Shape: (None, None, None, 256), Output Shape: (None, None, None, 256)\n",
      "Layer Name: block3_conv3, Input Shape: (None, None, None, 256), Output Shape: (None, None, None, 256)\n",
      "Layer Name: block3_pool, Input Shape: (None, None, None, 256), Output Shape: (None, None, None, 256)\n",
      "Layer Name: block4_conv1, Input Shape: (None, None, None, 256), Output Shape: (None, None, None, 512)\n",
      "Layer Name: block4_conv2, Input Shape: (None, None, None, 512), Output Shape: (None, None, None, 512)\n",
      "Layer Name: block4_conv3, Input Shape: (None, None, None, 512), Output Shape: (None, None, None, 512)\n",
      "Layer Name: block4_pool, Input Shape: (None, None, None, 512), Output Shape: (None, None, None, 512)\n",
      "Layer Name: block5_conv1, Input Shape: (None, None, None, 512), Output Shape: (None, None, None, 512)\n",
      "Layer Name: block5_conv2, Input Shape: (None, None, None, 512), Output Shape: (None, None, None, 512)\n",
      "Layer Name: block5_conv3, Input Shape: (None, None, None, 512), Output Shape: (None, None, None, 512)\n",
      "Layer Name: block5_pool, Input Shape: (None, None, None, 512), Output Shape: (None, None, None, 512)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.applications.vgg16 import VGG16, decode_predictions, preprocess_input\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "model = VGG16(weights='imagenet', include_top=False)  # Load without the top classification layers\n",
    "\n",
    "# Get summary of the model's architecture\n",
    "model.summary()\n",
    "\n",
    "# Get information about the layers\n",
    "for layer in model.layers:\n",
    "    print(f\"Layer Name: {layer.name}, Input Shape: {layer.input_shape}, Output Shape: {layer.output_shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 296ms/step\n",
      "Predicted class: ('n04285008', 'sports_car', 0.9579621)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "# Load an image and pre-process it\n",
    "img_path = \"MCL750s.jpg\"  # Replace with your image path\n",
    "img = load_img(img_path, target_size=(224, 224))  # Resize to match VGG16 input size\n",
    "x = img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)  # Add batch dimension\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# Predict the class using VGG16 (requires loading top layers)\n",
    "model = VGG16(weights='imagenet')  # Load with top layers\n",
    "predictions = model.predict(x)\n",
    "predicted_class = decode_predictions(predictions, top=4)[0][0]\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 210ms/step\n"
     ]
    }
   ],
   "source": [
    "# Freeze convolutional base layers to prevent them from being updated during training\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Use the model as a feature extractor\n",
    "feature_output = model.predict(x)  # Extract features from the convolutional base\n",
    "\n",
    "# Use the extracted features for downstream tasks (e.g., classification, clustering)\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 138870800\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "# Add new layers on top of the frozen base\n",
    "num_classes = 1000  # Adjust based on your classification task\n",
    "new_model = keras.Sequential([\n",
    "    model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the total number of parameters\n",
    "print(f\"Total number of parameters: {new_model.count_params()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze only the convolutional base layers, allowing the rest to be trained\n",
    "for layer in new_model.layers[:15]:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 1000)              138357544 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1000)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               256256    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1000)              257000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138870800 (529.75 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 138870800 (529.75 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
