{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ngrams using numpy and spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram:  ['A', 'cat', 'in', 'the', 'big', 'bag']\n",
      "2-gram:  ['A cat', 'cat in', 'in the', 'the big', 'big bag']\n",
      "3-gram:  ['A cat in', 'cat in the', 'in the big', 'the big bag']\n",
      "4-gram:  ['A cat in the', 'cat in the big', 'in the big bag']\n"
     ]
    }
   ],
   "source": [
    "#ngram using nltk\n",
    "\n",
    "from nltk.util import ngrams\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def extract_ngrams(data, num):\n",
    "    n = ngrams(word_tokenize(data), num)\n",
    "    return [' '.join(grams) for grams in n]\n",
    "\n",
    "data = input(\"Enter Sentence: \")\n",
    "print(\"1-gram: \", extract_ngrams(data, 1))\n",
    "print(\"2-gram: \", extract_ngrams(data, 2))\n",
    "print(\"3-gram: \", extract_ngrams(data, 3))\n",
    "print(\"4-gram: \", extract_ngrams(data, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram:  ['a', 'cat', 'in', 'a', 'big', 'bag']\n",
      "2-gram:  ['a cat', 'cat in', 'in a', 'a big', 'big bag']\n",
      "3-gram:  ['a cat in', 'cat in a', 'in a big', 'a big bag']\n",
      "4-gram:  ['a cat in a', 'cat in a big', 'in a big bag']\n"
     ]
    }
   ],
   "source": [
    "#ngram using nltk\n",
    "\n",
    "from textblob import TextBlob\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def extract_ngrams(data, num):\n",
    "    n = TextBlob(data).ngrams(num)\n",
    "    return [' '.join(grams) for grams in n]\n",
    "\n",
    "data = input(\"Enter Sentence: \")\n",
    "print(\"1-gram: \", extract_ngrams(data, 1))\n",
    "print(\"2-gram: \", extract_ngrams(data, 2))\n",
    "print(\"3-gram: \", extract_ngrams(data, 3))\n",
    "print(\"4-gram: \", extract_ngrams(data, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Download the Reuters corpus if not already present\n",
    "nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = defaultdict(lambda: defaultdict(lambda: 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process the corpus\n",
    "corpus = reuters.sents()  # Get sentences\n",
    "corpus = [' '.join(sent) for sent in corpus]  # Join words in each sentence\n",
    "\n",
    "# Generate trigrams\n",
    "trigrams = list(nltk.trigrams(word for sent in corpus for word in sent.split()))\n",
    "\n",
    "# Count trigram frequencies\n",
    "trigram_counts = nltk.FreqDist(trigrams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate trigram probabilities\n",
    "def trigram_probability(w1, w2, w3):\n",
    "    trigram_count = trigram_counts[(w1, w2, w3)]\n",
    "    bigram_count = trigram_counts[(w1, w2)]\n",
    "    return trigram_count / bigram_count if bigram_count > 0 else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Example usage: Calculate the probability of a word given two previous words\n",
    "probability = trigram_probability(\"once\", \"upon\", \"a\")\n",
    "print(probability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "# Download the Reuters corpus if not already present\n",
    "nltk.download('reuters')\n",
    "\n",
    "# Process the corpus\n",
    "corpus = reuters.sents()  # Get sentences\n",
    "corpus = [' '.join(sent) for sent in corpus]  # Join words in each sentence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate trigrams and bigrams\n",
    "trigrams = list(nltk.trigrams(word for sent in corpus for word in sent.split()))\n",
    "bigrams = list(nltk.bigrams(word for sent in corpus for word in sent.split()))\n",
    "\n",
    "# Count trigram and bigram frequencies\n",
    "trigram_counts = nltk.FreqDist(trigrams)\n",
    "bigram_counts = nltk.FreqDist(bigrams)\n",
    "\n",
    "# Function to predict the third word using trigrams and bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "River\n"
     ]
    }
   ],
   "source": [
    "def predict_third_word(w1, w2):\n",
    "    # Check for trigrams first\n",
    "    trigram_candidates = sorted(\n",
    "        trigram_counts.items(), key=lambda item: item[1], reverse=True\n",
    "    )\n",
    "    for w3, count in trigram_candidates:\n",
    "        if w1 == w3[0] and w2 == w3[1]:\n",
    "            return w3[2]\n",
    "\n",
    "    # Fallback to bigrams if no trigram match\n",
    "    bigram_candidates = sorted(\n",
    "        bigram_counts.items(), key=lambda item: item[1], reverse=True\n",
    "    )\n",
    "    for w3, count in bigram_candidates:\n",
    "        if w2 == w3[0]:\n",
    "            return w3[1]\n",
    "\n",
    "    # If no bigram match, return a generic placeholder\n",
    "    return \"<UNK>\"\n",
    "\n",
    "# Example usage: Predict the third word\n",
    "predicted_word = predict_third_word(\"The\", \"Red\")\n",
    "print(predicted_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in reuters.sents():\n",
    "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "        model[(w1, w2)][w3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
